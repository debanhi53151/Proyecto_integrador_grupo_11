## Proyecto Integrador (I) ‚Äî SLAM en entornos log√≠sticos con robot MiR100.

# 1. Enunciado.

En este proyecto integrador se implementa un sistema SLAM (Simultaneous Localization and 
Mapping) para el robot m√≥vil diferencial MiR100 en entornos log√≠sticos semiestructurados como lo 
es en un ambiente log√≠stico dentro de una empresa como lo es un almac√©n con pasillos definidos, 
estaciones fijas y zonas de cruce. 

Este ejercicio se elabora mediante la construcci√≥n de un mapa con percepci√≥n sensorial en un robot 
m√≥vil. Puesto que el objetivo de este proyecto es implementar un algoritmo de construcci√≥n de 
mapas de ocupaci√≥n usando la informaci√≥n que viene de un sensor de ultrasonidos colocado sobre 
el robot m√≥vil como tipo diferencial para lograr un mapa preciso a partir de los datos reales de 
sensores y tambi√©n integrando LiDAR 2D, odometr√≠a y IMU, incluyendo par√°metros ajustados a la 
log√≠stica para mejorar precisi√≥n, robustez y consistencia (Thrun et al., 2005, caps. 6 y 9; Yue & 
He, 2024). 

Puesto que el mapa generado ser√° una representaci√≥n en rejilla de cada celda almacena la 
probabilidad de estar ocupada o libre, que se representa en log-odds. Cada lectura del sensor, el 
mapa se ira actualizando de forma acumulativa y lineal, vi√©ndose reflejado la evidencia de la 
recolecci√≥n a lo largo del recorrido (Thrun et al., 2005, cap. 9). 

La soluci√≥n se basar√° en modelos probabil√≠sticos de movimiento, medici√≥n y t√©cnicas de SLAM de 
las cuales son AMCL, GraphSLAM, FastSLAM, Occupancy Grid, que se toman en cuenta seg√∫n las 
recomendaciones del libro Probabilistic Robotics y est√°ndares de evaluaci√≥n de desempe√±o 
para AGVs (Thrun et al., 2005, caps. 5‚Äì6, 8‚Äì13; Bostelman, 2016). 

‚Ä¢ En un entorno del robot ser√° representada en log√≠stico que se representa en un mapa de 
2D en rejilla con una resoluci√≥n de 5 cm por celda, tambi√©n una imagen de 500x500 
pixeles con escala de 5 cm por pixel para la superposici√≥n visual (Thrun et al., 2005, cap. 
9). 

‚Ä¢ El robot MiR100 se desplaza en un entorno y recolecta informaci√≥n mediante el LiDAR 
2D con ‚â•‚ÄØ270¬∞, un alcance de 30 m y el IMU; tambi√©n la odometr√≠a de lo encoders se usa 
para reconstruir la pose y orientaci√≥n (Peng et al., 2023; Yue & He, 2024). 
‚Ä¢ Mediante los encoders de cada rueda y la cinem√°tica diferencial se va reconstruyendo la 
trayectoria del robot m√≥vil; de manera opcional se estabiliza con el AMCL, FastSLAM, 
GraphSLAM, es decir, manteniendo coherencia TF (Open Robotics, 2025; Thrun et al., 
2005, caps. 8 y 11). 

‚Ä¢ Con la recolecci√≥n de informaci√≥n sensorial, se actualiza el mapa ocupaci√≥n usando 
modelo inverso, dado que refuerza ocupada entorno o retornos y libre antes del retorno 
a lo largo del rayo (Thrun et al., 2005, cap. 6). 

‚Ä¢ Finalmente se mostrar√° la trayectoria seguida en las zonas ocupadas junto las de 
superposici√≥n con el mapa de referencia de rosbag con sus m√©tricas de calidad y las 
guias de ASTM F45 (Thrun et al., 2005; Bostelman, 2016). 

<img width="199" height="228" alt="image" src="https://github.com/user-attachments/assets/6b50abd3-cd29-4e32-b84d-471b98b97d46" />

<img width="506" height="217" alt="image" src="https://github.com/user-attachments/assets/0ab6a559-26c1-4cd5-9ccc-db132145392a" />

# 2. Objetivos. 

‚Ä¢ Es la construcci√≥n de mapa precisos que se recolecta a partir de datos reales de sensores 
con ello garantizando la robustez ante los obst√°culos y condiciones que pueden generar 
variables de error. 

‚Ä¢ Comprender el pipeline de SLAM en la adquisici√≥n, preprocesado, estimaci√≥n y validaci√≥n 
(Yue & He, 2024; Thrun et al., 2005). 

‚Ä¢ Selecci√≥n y justificaci√≥n de la t√©cnica de mapeo m√°s id√≥nea para el proyecto (Thrun et al., 
2005). 

‚Ä¢ Implementaci√≥n de un sistema sobre el rosbag del MiR100 con par√°metros nuevos. 

‚Ä¢ Evaluaci√≥n de la calidad del mapa y su trayectoria mediante m√©tricas cualitativas y 
cuantitativas (Thrun et al., 2005; Bostelman, 2016). 

‚Ä¢ Dise√±o con la explicaci√≥n de la arquitectura. 

# 2.1. Detalles de entrega 

Datos del rosbag. 

De lo cual contendr√° los siguientes mensajes: 

‚Ä¢ Sensores: /scan, /imu_data. 

‚Ä¢ Movimiento / control: /cmd_vel, /odom, /odometry/filtered, /joint_states, /mir/joint_states. 

‚Ä¢ Referencia: /base_pose_ground_truth, /amcl_pose, /particlecloud. 

‚Ä¢ Mapas: /map, /map_metadata, /map_updates. 

‚Ä¢ Transformaciones y tiempo: /tf, /tf_static, /clock 

‚Ä¢ Eventos de usuarios: /initialpose, /move_base_simple/goal. 

# 2.2. Lenguaje de programaci√≥n. 

El proyecto se har√° en Matlab el c√≥digo de programaci√≥n dado que los miembros del equipo, 
mediante una votaci√≥n y evaluaci√≥n se hizo m√°s favorable. 

El codigo principal esta en slam_mir100, de lo cual tiene archivos auxiliares que se crearon para que se pudiera funcionar y crear el entorno logistico de lo cuales son los siguientes archivos
1. analyze_bag.m
2. dibujarMapaOccupacion.
3
4
5
6
7
8
9
10.

# 3. Conceptos.

Mapas de ocupaci√≥n basados en rejillas. 

En este proyecto integrador en el entorno del almac√©n se va a representar en una rejilla 
bidimensional conocida como occupancy grid (Thrun et al., 2005, cap. 9). Cada celda almacena la 
posibilidad de estar ocupada, libre o desconocida; esto es fundamental en el SLAM dado que permite 
integrar lecturas sensoriales con la planificaci√≥n de rutas seguras en el entorno log√≠stico (Thrun et 
al., 2005; Yue & He, 2024). 

‚ñ™ Ocupada: es la presencia de un obst√°culo como es una pared, rack o pallet. 

‚ñ™ Libre: es aquel espacio sin obst√°culos y favorable para navegaci√≥n 

‚ñ™ Desconocida: es un estado inicial o con baja evidencia, es decir, sin mediciones suficientes. 

Puesto que esta representaci√≥n es est√°ndar en lo algoritmos que son ampliamente usados en los 
robots m√≥viles industriales de lo cuales entre ellos son el Gmapping, Hector SLAM y Cartographer. 
Representacion en log-odds. 

Para una actualizaci√≥n del mapa de manera eficiente y acumulativa, en cada celda se almacena el 
formato log-odds.

<img width="401" height="219" alt="image" src="https://github.com/user-attachments/assets/195cf18c-a07b-4f05-bb6d-237508791512" />

Actualizaci√≥n del mapa. 

Cada lectura nueva del LiDAR se traduce en log-odds y es acumulativa:

<img width="703" height="138" alt="image" src="https://github.com/user-attachments/assets/f81478c5-d342-4eb9-b5b1-231abb0b7b83" />

Este m√©todo est√° explicado en Probabilistic Robotics (Thrun et al., Cap. 9) y es la base de los 
mapas de ocupaci√≥n en SLAM. 

Componentes del sistema. 

Robot y movimiento. 

‚Ä¢ Robot MiR100 que utiliza odometr√≠a en los encoders, con un IMU y LiDAR 2D con un 
FoV ‚â• 270¬∞, alcance hasta 30 m. 

<img width="258" height="79" alt="image" src="https://github.com/user-attachments/assets/94721eb5-fa46-40a7-a940-fd9e5e29834d" />

 En el modelo del movimiento es cinematica diferencial para estimar la posici√≥n. 
Y el movimiento se describe de la siguiente manera: 

<img width="204" height="113" alt="image" src="https://github.com/user-attachments/assets/04a3f182-33bd-4dd5-b3bf-be358f93b2bf" />

(Thrun et al., 2005, cap. 5; Siegwart, Nourbakhsh, & Scaramuzza, 2011, cap. 3). 

Sensor LiDAR es el simula que cada escaneo de rayos que detecta el primer obst√°culo que se 
encuentre en su recorrido con apertura efectiva Œ±=20¬∞ y actualiza las celdas, porque tiene un 
alcance de ùëüùëöùëéùë• = 30 m, de lo cual depender√° de la zona: 

<img width="520" height="75" alt="image" src="https://github.com/user-attachments/assets/2dbae26a-5896-4eff-9d13-71b5242c0450" />

Planificaci√≥n de movimiento 

Escogido el mapa en el punto anterior, se ha adoptado el algoritmo mejorado A* gracias a su perfecto 
encaje con las occupancy grids debido a que opera directamente sobre celdas discretas 
aprovechando sus estructuras regulares y permitiendo calcular costes y heur√≠sticas eficientes. 
Adem√°s, este tipo de representaci√≥n puede obtener un alto grado de optimizaci√≥n en la penalizaci√≥n 
angular favoreciendo trayectorias m√°s rectas reduciendo el n√∫mero de giros innecesarios, reducci√≥n 
de n√∫meros puntos de paso o waypoints y de nodos redundantes. 

Para llevar a cabo esta optimizaci√≥n en el MiR100, se ha optado por los siguientes tres puntos: - - - 

Introducci√≥n de t√©rminos de coste angular y estrategias de tie-breaking, favoreciendo a la 
priorizaci√≥n de segmentos rectos para reducir el n√∫mero de giros y cambios de rumbo en 
zonas extensas como pudieran ser pasillos largos (*1).   

Ajuste en el n√∫mero de nodos donde el robot decide, en funci√≥n de contexto de la zona de 
trabajo, optar por un modelo 4-vecinos o de 8-vecinos. En caso de actuar en un pasillo o 
zona estrecha trabajar√≠a con el modelo de 4-vecinos. En cambio, en un espacio m√°s abierto 
la decisi√≥n que debe tomar es la de aplicar el modelo 8-vecinos ayudando a que el 
movimiento pueda tomar trayectorias m√°s diagonales (*2). 

Eliminaci√≥n de nodos redundantes para una optimizaci√≥n en el n√∫mero de waypoints o 
puntos de paso (*3). 

La ecuaci√≥n empleada para este proyecto es la siguiente: 

<img width="214" height="105" alt="image" src="https://github.com/user-attachments/assets/ce4b6901-38a3-471f-ac21-47558f98c4d3" />

<img width="565" height="123" alt="image" src="https://github.com/user-attachments/assets/675133c8-0023-4beb-b38a-f540fa164b6f" />

<img width="290" height="368" alt="image" src="https://github.com/user-attachments/assets/35504998-eb22-493c-8e21-9f0071ace3e4" />

<img width="445" height="451" alt="image" src="https://github.com/user-attachments/assets/113fe3ae-d987-44aa-bae9-6609180f4fc5" />

En el presente diagrama de arquitectura de soluci√≥n representa una estructura viable para el sistema 
SLAM que es aplicado en un robot MiR100, de lo cual estima su propia posici√≥n, usando datos 
sensoriales que son extra√≠dos del rosbag. 

En el bloque azul 1 Sensores , de lo cual como se puede ver en la entrada esta el archivo ROSBAG 
que tiene los siguientes t√≥picos como /odom (odometr√≠a) y /scan (LiDAR); por lo cual los sensores 
dan informaci√≥n sobre la pose del robot junto con las distancias a los obst√°culos. Fundamentado con 
lo redactado por Thrun, Burgard y Fox (2005), esta combinaci√≥n es esencial para que los sensores 
den la estimaci√≥n de probabil√≠stica del estado y del entorno. 

En los bloques de color anaranjado es el procesamiento, de lo cual esta dividido en tres bloques que 
son: 

La incializacion del mapa en log-odds que este crea una matriz de ocupaci√≥n mediante la 
incertidumbre inicial = 0.5, aqu√≠ el log-odds es para facilitar la suma de evidencias (Stachniss et al., 
2006). 

El segundo es el modelo inverso que es la actualizaci√≥n de cada celda del mapa seg√∫n las lecturas 
del LiDAR, que se asignan como ocupadas, libres o inciertas. 

El tercero es la actualizaci√≥n del mapa que es donde se acumulas evidencias sensoriales de cada 
celda mediante la formula de modelo Bayesiano que es fundamento por Leonard y Durrant-Whyte 
(2001), que la observaci√≥n refina la creencia del estado en el entorno. 

El bloque verde de visualizaci√≥n es la salida del sistema, donde incluye dos cosas:  Mapa de 
ocupaci√≥n que este elabora la conversi√≥n de log-odds a las probabildades para representar zonas 
ocupadas y libres. El segundo es la trayectoria del robot que se superpone a la trayectoria estimada 
sobre el mapa, esto valida el desempe√±o de SLAM. Esta visualizaci√≥n se usa para evaluar la precisi√≥n
del sistema como lo describe Stachniss et al. (2006) quien destaca la importancia de la comparaci√≥n 
de trayectorias que son como referencias externas.

<img width="672" height="418" alt="image" src="https://github.com/user-attachments/assets/3442b7e1-5026-456f-b4c0-f3a4a9b15e95" />

Referencias (APA). 

‚Ä¢ Abu Bakar, M. A., Kamarudin, K., Qistina, N., Heng, H., Imran, H., & Rahiman, W. (2025). 
Parameters tuning for enhanced automated guided vehicle navigation in ROS/Gazebo 
simulation environment. Journal of Advanced Research in Applied Mechanics, 133(1), 63
77. 

‚Ä¢ Bostelman, R. (2016). Navigation performance evaluation for automatic guided vehicles. National Institute of Standards and Technology 
https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=918241 [github.com] 
(NIST). 

‚Ä¢ Open Robotics Discourse. (2025). Learn ROS AI Robotics Integration with New 
Launched 
Logistics 
https://discourse.openrobotics.org/t/learn-ros-ai-robotics-integration-with-new-launched
logistics-kit/43466 [cs.columbia.edu] 
Kit. 

‚Ä¢ Peng, G., et al. (2023). LiDAR SLAM for mobile robot. In Introduction to Intelligent Robot System Design. Springer. 
https://link.springer.com/chapter/10.1007/978-981-96-4967-9_56 

‚Ä¢ Siegwart, R., Nourbakhsh, I. R., & Scaramuzza, D. (2011). Introduction to Autonomous 
Mobile Robots (2nd ed.). MIT Press. (Cap.‚ÄØ3: cinem√°tica diferencial). 
‚Ä¢ Thrun, S., Burgard, W., & Fox, D. (2005). Probabilistic Robotics. MIT Press. (Caps.‚ÄØ5‚Äì6, 
8‚Äì9, 10‚Äì13). 

‚Ä¢ Yue, X., & He, M. (2024). LiDAR-based SLAM for robotic mapping: State of the art and new frontiers. 
https://arxiv.org/abs/2311.00276 [aicompetence.org] 

‚Ä¢ MathWorks. (s.‚ÄØf.). arXiv lidarSLAM https://www.mathworks.com/help/nav/ref/lidarslam.html preprint. (MATLAB). 

‚Ä¢ (*1) Xie, J., Xu, C., & Yang, Q. (2025). Robot path planning model based on improved A 
algorithm*. International Journal of Advanced Computer Science and Applications, 16(5). 

‚Ä¢ (2*) Mi, Z. (2024). Robot path planning based on improved A algorithm*. IEEE Xplore. 

‚Ä¢ (*3) Wang, F., Sun, W., Yan, P., Wei, H., & Lu, H. (2024). Research on path planning for 
robots with improved A algorithm under bidirectional JPS strategy*. Applied Sciences, 14(13).









